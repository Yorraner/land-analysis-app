import streamlit as st
import os
import pandas as pd
import time
import json
import zipfile
import shutil
from utils_pdf import extract_section_to_pdf, extract_section_to_pdf_self, extract_info,parser_file
from api_client import CozeClient, get_mock_data, WORKFLOW_CONFIG 
from utils_fusion import unify_and_concatenate, preprocess_X # å¼•å…¥å½’ä¸€åŒ–å‡½æ•°
from utils_vis import plot_heatmap # å¼•å…¥å¯è§†åŒ–

# from utils_parsers import process_raw_data
# from utils_fusion import unify_and_concatenate

# === é¡µé¢é…ç½® ===
st.set_page_config(page_title="åœŸåœ°æ•´æ²»æ™ºèƒ½åˆ†æå¹³å°", layout="wide")
st.title("ğŸ—ï¸ åœŸåœ°æ•´æ²»æ–‡æ¡£æ™ºèƒ½åˆ†ç±»ç³»ç»Ÿ")

# === ä¸´æ—¶æ–‡ä»¶ç®¡ç† ===
TEMP_DIR = "temp_workspace"
DIRS = {
    "upload": os.path.join(TEMP_DIR, "1_uploads"),
    "crop": os.path.join(TEMP_DIR, "2_cropped"),
    "raw": os.path.join(TEMP_DIR, "3_raw_data"),
    "result": os.path.join(TEMP_DIR, "4_results")
}

# åˆå§‹åŒ–ç›®å½•
for d in DIRS.values():
    if not os.path.exists(d): os.makedirs(d)

# === ä¾§è¾¹æ ï¼šæµç¨‹æ§åˆ¶ ===
with st.sidebar:
    st.header("å·¥ä½œæµå¯¼èˆª")
    step = st.radio("é€‰æ‹©æ­¥éª¤", [
        "1. æ–‡æ¡£ä¸Šä¼ ä¸è£å‰ª", 
        "2. å¤§æ¨¡å‹æ•°æ®è·å–", 
        "3. æ•°æ®è§£æ", 
        "4. æ•°æ®èåˆ&å±•ç¤º",
        "5. æ•°æ®åˆ†ç±»ä¸å¯¼å‡º"
    ])
    
    st.divider()
    if st.button("æ¸…ç†ä¸´æ—¶æ–‡ä»¶"):
        if os.path.exists(TEMP_DIR):
            shutil.rmtree(TEMP_DIR)
            for d in DIRS.values():
                if not os.path.exists(d): os.makedirs(d)
        st.success("å·²æ¸…ç†ç¼“å­˜")

# ========================================================
# 1. ä¸Šä¼ ä¸è£å‰ª
# ========================================================
if step == "1. æ–‡æ¡£ä¸Šä¼ ä¸è£å‰ª":
    st.header("ğŸ“„ æ­¥éª¤ 1: PDF æ–‡æ¡£å¤„ç†")
    
    tab1, tab2 = st.tabs(["ğŸš€ æ‰¹é‡è‡ªåŠ¨è£å‰ª", "ğŸ› ï¸ æ‰‹åŠ¨è£å‰ªä¿®å¤"])
    
    # --- Tab 1: è‡ªåŠ¨è£å‰ª ---
    with tab1:
        st.markdown("ä¸Šä¼ åŸå§‹æ–‡æ¡£ï¼Œç³»ç»Ÿå°†è‡ªåŠ¨è¯†åˆ«å¹¶è£å‰ªåŒ…å«å…³é”®è¯ï¼ˆå¦‚â€œå­˜åœ¨é—®é¢˜â€ï¼‰çš„ç« èŠ‚ã€‚")
        uploaded_files = st.file_uploader("ä¸Šä¼  PDF æ–‡ä»¶", type=["pdf"], accept_multiple_files=True, key="auto_uploader")
        keyword = st.text_input("ç« èŠ‚å…³é”®è¯", value="å­˜åœ¨é—®é¢˜")
        
        if st.button("å¼€å§‹è‡ªåŠ¨è£å‰ª", type="primary"):
            if not uploaded_files:
                st.error("è¯·å…ˆä¸Šä¼ æ–‡ä»¶ï¼")
            else:
                bar = st.progress(0)
                status = st.empty()
                success_count = 0
                for i, f in enumerate(uploaded_files):
                    src_path = os.path.join(DIRS["upload"], f.name)
                    with open(src_path, "wb") as buffer: buffer.write(f.getbuffer())
                    
                    status.text(f"æ­£åœ¨å¤„ç†: {f.name}...")
                    
                    # 1. æå–ä¿¡æ¯
                    info = extract_info(f.name)
                    clean_region_name = info["æ–°æ–‡ä»¶å"]
                    
                    # 2. æ„é€ æ–°æ–‡ä»¶å: åœ°åŒºå_å…³é”®è¯.pdf (ä¾‹å¦‚: æ½®å·-æ¹˜æ¡¥_é—®é¢˜.pdf)
                    dst_name = f"{clean_region_name}_{keyword}.pdf"
                    dst_path = os.path.join(DIRS["crop"], dst_name)
                    
                    # 3. æ‰§è¡Œè£å‰ª
                    if extract_section_to_pdf(src_path, dst_path, keyword): 
                        success_count += 1
                        # å¯é€‰ï¼šæ˜¾ç¤ºé‡å‘½åç»“æœ
                        # st.caption(f"å·²ä¿å­˜ä¸º: {dst_name}")
                    
                    bar.progress((i + 1) / len(uploaded_files))
                
                if success_count == len(uploaded_files): 
                    st.success(f"âœ… å…¨éƒ¨å¤„ç†å®Œæˆï¼æˆåŠŸ {success_count} ä¸ªã€‚")
                else: 
                    st.warning(f"âš ï¸ æˆåŠŸ {success_count} ä¸ªï¼Œå¤±è´¥ {len(uploaded_files)-success_count} ä¸ªã€‚")

    # --- Tab 2: æ‰‹åŠ¨è£å‰ª ---
    with tab2:
        st.markdown("é’ˆå¯¹è‡ªåŠ¨è¯†åˆ«å¤±è´¥çš„æ–‡ä»¶ï¼Œ**æ‰‹åŠ¨æŒ‡å®šèµ·æ­¢é¡µç **è¿›è¡Œæå–ã€‚")
        existing_files = [f for f in os.listdir(DIRS["upload"]) if f.endswith(".pdf")]
        col_up, col_sel = st.columns([1, 2])
        with col_up: manual_file = st.file_uploader("ä¸Šä¼ å•ä¸ªæ–‡ä»¶", type=["pdf"], key="manual_uploader")
        target_file_path = None
        if manual_file:
            target_file_path = os.path.join(DIRS["upload"], manual_file.name)
            with open(target_file_path, "wb") as f: f.write(manual_file.getbuffer())
            st.info(f"å·²é€‰ä¸­: {manual_file.name}")
        elif existing_files:
            sel = col_sel.selectbox("é€‰æ‹©å·²ä¸Šä¼ æ–‡ä»¶", existing_files)
            if sel: target_file_path = os.path.join(DIRS["upload"], sel)
        
        if target_file_path:
            st.divider()
            c1, c2, c3 = st.columns([1, 1, 2])
            with c1: start_p = st.number_input("èµ·å§‹é¡µç ", min_value=1, value=1)
            with c2: end_p = st.number_input("ç»“æŸé¡µç ", min_value=1, value=5)
            with c3: 
                st.write(""); st.write("")
                if st.button("âœ‚ï¸ æ‰§è¡Œè£å‰ª"):
                    if end_p <= start_p: st.error("ç»“æŸé¡µç å¿…é¡»å¤§äºèµ·å§‹é¡µç ï¼")
                    else:
                        f_name = os.path.basename(target_file_path)
                        
                        # === ä¿®æ”¹ç‚¹ï¼šæ‰‹åŠ¨è£å‰ªä¹Ÿå°è¯•è§„èŒƒåŒ–å‘½å ===
                        info = extract_info(f_name)
                        # æ‰‹åŠ¨è£å‰ªé€šå¸¸æ˜¯ä¸ºäº†ä¿®å¤æŸä¸ªç‰¹å®šé—®é¢˜ï¼Œè¿™é‡ŒåŠ ä¸Š _manual åç¼€ä»¥ç¤ºåŒºåˆ«
                        # æˆ–è€…å¦‚æœæ‚¨å¸Œæœ›æ‰‹åŠ¨ä¿®å¤çš„æ–‡ä»¶ä¹Ÿèƒ½ç›´æ¥è¢« API è¯†åˆ«ï¼Œå¯ä»¥å»æ‰ _manualï¼Œ
                        # ä½†ä¸ºäº†é˜²æ­¢è¦†ç›–è‡ªåŠ¨ç”Ÿæˆçš„æ–‡ä»¶ï¼Œå»ºè®®ä¿ç•™æ ‡è¯†ã€‚
                        # è¿™é‡Œæˆ‘ä»¬ä½¿ç”¨: åœ°åŒºå_manual.pdf
                        dst_name = f"{info['æ–°æ–‡ä»¶å']}_manual.pdf"
                        dst_path = os.path.join(DIRS["crop"], dst_name)
                        
                        if extract_section_to_pdf_self(target_file_path, start_p, end_p, dst_path):
                            st.success(f"âœ… è£å‰ªæˆåŠŸï¼å·²ä¿å­˜ä¸º: {dst_name}")
                        else: st.error("âŒ è£å‰ªå¤±è´¥")

    st.divider()
    # === æ–°å¢ï¼šæ–‡ä»¶æŸ¥çœ‹ä¸ä¸‹è½½åŒºåŸŸ ===
    st.subheader("ğŸ“‚ ç»“æœæ–‡ä»¶ç®¡ç†")
    
    cropped_files = []
    if os.path.exists(DIRS["crop"]):
        cropped_files = [f for f in os.listdir(DIRS["crop"]) if f.endswith(".pdf")]
    
    if cropped_files:
        # 1. åˆ—è¡¨å±•ç¤º
        st.dataframe(pd.DataFrame(cropped_files, columns=["å·²ç”Ÿæˆçš„æ–‡ä»¶å"]), use_container_width=True, height=200)
        
        col_d1, col_d2 = st.columns(2)
        
        # 2. æ‰¹é‡æ‰“åŒ…ä¸‹è½½åŠŸèƒ½
        with col_d1:
            zip_path = os.path.join(TEMP_DIR, "cropped_files.zip")
            with zipfile.ZipFile(zip_path, 'w') as zipf:
                for f in cropped_files:
                    zipf.write(os.path.join(DIRS["crop"], f), f)
            
            with open(zip_path, "rb") as f:
                st.download_button(
                    label="ğŸ“¦ æ‰“åŒ…ä¸‹è½½æ‰€æœ‰æ–‡ä»¶ (.zip)",
                    data=f,
                    file_name="cropped_files.zip",
                    mime="application/zip",
                    type="primary"
                )
        
        # 3. å•æ–‡ä»¶ä¸‹è½½åŠŸèƒ½
        with col_d2:
            selected_download = st.selectbox("æˆ–è€…é€‰æ‹©å•ä¸ªæ–‡ä»¶ä¸‹è½½:", cropped_files)
            if selected_download:
                file_path = os.path.join(DIRS["crop"], selected_download)
                with open(file_path, "rb") as f:
                    st.download_button(
                        label=f"ğŸ“„ ä¸‹è½½ {selected_download}",
                        data=f,
                        file_name=selected_download,
                        mime="application/pdf"
                    )
    else:
        st.info("æš‚æ— å¤„ç†å¥½çš„æ–‡ä»¶ï¼Œè¯·å…ˆæ‰§è¡Œè£å‰ªæ“ä½œã€‚")
# ========================================================
# 2. æ•°æ®æå– (API)
# ========================================================
elif step == "2. å¤§æ¨¡å‹æ•°æ®è·å–":
    st.header("ğŸ¤– æ­¥éª¤ 2: è°ƒç”¨å¤§æ¨¡å‹æ™ºèƒ½ä½“è·å–æ•°æ®")
    
    # 1. æ‰«ææ–‡ä»¶
    files = [f for f in os.listdir(DIRS["crop"]) if f.endswith(".pdf")]
    
    if not files:
        st.warning("âš ï¸ æš‚æ— å·²è£å‰ªæ–‡ä»¶ï¼Œè¯·å…ˆå®Œæˆæ­¥éª¤ 1ã€‚")
    else:
        # 2. æ–‡ä»¶åæ¸…æ´—é¢„è§ˆ
        st.subheader("1ï¸âƒ£ æ–‡ä»¶åæ¸…æ´—ä¸åœ°åŒºè¯†åˆ«")
        file_info_list = []
        for f in files:
            info = parser_file(f) # è°ƒç”¨ utils_pdf ä¸­çš„æ–°å‡½æ•°
            file_info_list.append(info)
        
        info_df = pd.DataFrame(file_info_list)
        st.dataframe(info_df[["æ–‡ä»¶å", "åŸå¸‚", "åœ°åŒº/å¿","è¯¦ç»†å•å…ƒ"]], use_container_width=True)

        st.divider()
        
        # 3. ä»»åŠ¡é…ç½®
        st.subheader("2ï¸âƒ£ å¼€å§‹æå–")
        col1, col2 = st.columns([1, 1])
        with col1:
            task_type = st.selectbox("é€‰æ‹©åˆ†æä»»åŠ¡ç±»å‹", ["æ•´æ²»æ½œåŠ›", "åœŸåœ°åˆ©ç”¨ç°çŠ¶", "å­˜åœ¨é—®é¢˜", "å­é¡¹ç›®"])
        with col2:
            use_mock = st.checkbox("ä½¿ç”¨æ¨¡æ‹Ÿæ•°æ® (è°ƒè¯•ç”¨)", value=True)
            
        if st.button("ğŸš€ å‘é€è‡³æ‰£å­(Coze)è¿›è¡Œåˆ†æ", type="primary"):
            # åˆå§‹åŒ–ç»“æœå®¹å™¨
            results = []
            progress_bar = st.progress(0)
            log_container = st.container() # ç”¨äºæ˜¾ç¤ºå®æ—¶æ—¥å¿—
            
            # åˆå§‹åŒ–å®¢æˆ·ç«¯
            client = None
            if not use_mock:
                client = CozeClient() 
                workflow_id = WORKFLOW_CONFIG.get(task_type)
            
            # å¼€å§‹å¾ªç¯å¤„ç†
            for i, info in enumerate(file_info_list):
                file_name = info["åŸå§‹æ–‡ä»¶å"]
                # è¿™é‡Œçš„â€œæ–°æ–‡ä»¶åâ€å®é™…ä¸Šå°±æ˜¯æ­¥éª¤1ç”Ÿæˆçš„è§„èŒƒåŒ–æ–‡ä»¶å (ä¾‹å¦‚: æ½®å·-æ¹˜æ¡¥_é—®é¢˜)

                region_name = info["æ–°æ–‡ä»¶å"] 
                
                file_path = os.path.join(DIRS["crop"], file_name)
                
                # --- UI æ˜¾ç¤ºå½“å‰çŠ¶æ€ ---
                with log_container:
                    status_expander = st.expander(f"ğŸ”„ æ­£åœ¨å¤„ç†: {region_name} ...", expanded=True)
                    with status_expander:
                        st.write(f"ğŸ“„ æ–‡ä»¶: `{file_name}`")
                        
                        # --- è°ƒç”¨ API ---
                        raw_data = None
                        try:
                            if use_mock:
                                time.sleep(0.5)
                                raw_data = get_mock_data(file_path, task_type)
                                st.info("âœ… æ¨¡æ‹Ÿæ•°æ®è·å–æˆåŠŸ")
                            else:
                                if not workflow_id:
                                    st.error(f"âŒ æœªé…ç½® {task_type} çš„ Workflow ID")
                                else:
                                    # 1. ä¸Šä¼ 
                                    st.write("ğŸ“¤ ä¸Šä¼ æ–‡ä»¶ä¸­...")
                                    file_id = client.upload_file(file_path)
                                    if file_id:
                                        # 2. æ‰§è¡Œ
                                        st.write("ğŸ¤– AI æ€è€ƒä¸­...")
                                        raw_data = client.run_workflow(workflow_id, file_id)
                                        if raw_data:
                                            st.success("âœ… å·¥ä½œæµæ‰§è¡ŒæˆåŠŸ")
                                        else:
                                            st.error("âŒ å·¥ä½œæµè¿”å›ä¸ºç©º")
                                    else:
                                        st.error("âŒ ä¸Šä¼ å¤±è´¥")
                                    time.sleep(1) # é™æµä¿æŠ¤
                        except Exception as e:
                            st.error(f"âŒ å‘ç”Ÿå¼‚å¸¸: {e}")
                        
                        # --- æ˜¾ç¤ºè¾“å‡ºå†…å®¹ ---
                        if raw_data:
                            st.markdown("**ğŸ” è¾“å‡ºå†…å®¹é¢„è§ˆ:**")
                            # å°è¯•ç¾åŒ– JSON æ˜¾ç¤º
                            try:
                                json_data = json.loads(raw_data)
                                st.json(json_data)
                                # æå– output å­—æ®µé‡Œçš„çº¯æ–‡æœ¬å±•ç¤º
                                if "output" in json_data:
                                    st.text_area("Output æ–‡æœ¬", json_data["output"], height=100)
                            except:
                                st.text(raw_data)
                            
                            # ä¿å­˜ç»“æœ
                            results.append({
                                "åœ°åŒº": region_name,
                                "rawdata": raw_data,
                                "åŸå§‹æ–‡ä»¶å": file_name
                            })
                
                # æ›´æ–°æ€»è¿›åº¦
                progress_bar.progress((i + 1) / len(files))
            
            # å¾ªç¯ç»“æŸ
            st.success(f"ğŸ‰ æ‰€æœ‰æ–‡ä»¶å¤„ç†å®Œæˆï¼æˆåŠŸè·å– {len(results)} æ¡æ•°æ®ã€‚")
            
            # ä¿å­˜åˆ° CSV
            if results:
                df_result = pd.DataFrame(results)
                save_path = os.path.join(DIRS["raw"], "coze_raw_output.csv")
                df_result.to_csv(save_path, index=False, encoding='utf-8-sig')
                st.write(f"æ•°æ®å·²ä¿å­˜è‡³: `{save_path}`")
                st.dataframe(df_result.head())
# # ========================================================
# # 3. æ•°æ®è§£æ
# # ========================================================
elif step == "3. æ•°æ®è§£æ":
    st.header("ğŸ§¹ æ­¥éª¤ 3: ç»“æ„åŒ–è§£æ")
    
    raw_file = os.path.join(DIRS["raw"], "coze_raw_output.csv")
    if not os.path.exists(raw_file):
        st.warning("è¯·å…ˆå®Œæˆæ­¥éª¤ 2 è·å–åŸå§‹æ•°æ®ã€‚")
    else:
        df_raw = pd.read_csv(raw_file)
        st.write("åŸå§‹æ•°æ®é¢„è§ˆ:", df_raw.head(3))
        
        col1, col2 = st.columns([1, 1])
        with col1:
            parse_type = st.selectbox("é€‰æ‹©è§£ææ¨¡å¼", ["å­˜åœ¨é—®é¢˜", "æ•´æ²»æ½œåŠ›", "é¡¹ç›®æ±‡æ€»"])
        
        if col2.button("æ‰§è¡Œè§£æ"):
            parsed_df = process_raw_data(df_raw, parse_type)
            
            # åˆå¹¶åœ°åŒºåˆ—
            final_df = pd.concat([df_raw[['åœ°åŒº']], parsed_df], axis=1)
            
            # å­˜ä¸ºä¸­é—´ç»“æœ
            out_name = f"parsed_{parse_type}.csv"
            final_df.to_csv(os.path.join(DIRS["result"], out_name), index=False, encoding='utf-8-sig')
            
            st.success(f"è§£ææˆåŠŸï¼å·²ä¿å­˜ä¸º {out_name}")
            st.dataframe(final_df.head())

# # ========================================================
# # 4. æ•°æ®èåˆ
# # ========================================================
if step == "4. æ•°æ®èåˆ&å±•ç¤º":
    st.header("ğŸ”— æ­¥éª¤ 4: å¤šæºæ•°æ®èåˆ (NÃ—d çŸ©é˜µ)åŠå¯è§†åŒ–å±•ç¤º")
    
    # æ‰«æå·²è§£æçš„ CSV
    csvs = [f for f in os.listdir(DIRS["result"]) if f.startswith("parsed_")]
    
    if not csvs:
        st.warning("âš ï¸ æ²¡æœ‰æ‰¾åˆ°è§£æåçš„æ•°æ®æ–‡ä»¶ï¼Œè¯·å…ˆå®Œæˆæ­¥éª¤ 3ã€‚")
    else:
        st.write("é€‰æ‹©è¦å‚ä¸èåˆçš„æ•°æ®è¡¨ï¼ˆå»ºè®®å…¨é€‰ä»¥ä¿è¯ç‰¹å¾å®Œæ•´æ€§ï¼‰ï¼š")
        # é»˜è®¤é€‰ä¸­æ‰€æœ‰æ–‡ä»¶ï¼Œå¹¶å°è¯•æŒ‰ç…§æ‚¨çš„é€»è¾‘æ’åºï¼ˆæ¯”å¦‚ 1.è‡ªç„¶èµ„æº 2.æ½œåŠ›...ï¼‰
        # è¿™é‡Œç®€å•æŒ‰æ–‡ä»¶åæ’åº
        csvs.sort() 
        selected = st.multiselect("é€‰æ‹©æ–‡ä»¶", csvs, default=csvs)
        
        if st.button("å¼€å§‹èåˆä¸å½’ä¸€åŒ–", type="primary"):
            if not selected:
                st.error("è¯·è‡³å°‘é€‰æ‹©ä¸€ä¸ªæ–‡ä»¶ã€‚")
            else:
                matrices, maps, names = [], [], []
                
                # æŒ‰ç…§ç”¨æˆ·é€‰æ‹©çš„é¡ºåºè¯»å–
                # æ³¨æ„ï¼šå¦‚æœè¦ä¿è¯ preprocess_X çš„ç¡¬ç¼–ç ç´¢å¼•æœ‰æ•ˆï¼Œ
                # è¿™é‡Œè¯»å–æ–‡ä»¶çš„é¡ºåºå¿…é¡»éå¸¸ä¸¥æ ¼ï¼å»ºè®®åœ¨æ–‡ä»¶åä¸­åŠ å…¥å‰ç¼€å¦‚ "01_parsed_è‡ªç„¶èµ„æº..."
                # æˆ–è€…åœ¨è¿™é‡Œæ‰‹åŠ¨æŒ‡å®šé¡ºåºé€»è¾‘
                
                st.info("ğŸ’¡ æç¤ºï¼šæ­£åœ¨æ„å»ºåŸå§‹çŸ©é˜µ...")
                
                # ä¸ºäº†æ¼”ç¤ºï¼Œæˆ‘ä»¬å‡è®¾ selected é‡Œçš„æ–‡ä»¶é¡ºåºå°±æ˜¯æ­£ç¡®çš„é¡ºåº
                # å®é™…åº”ç”¨ä¸­ï¼Œæ‚¨å¯èƒ½éœ€è¦åœ¨è¿™é‡Œå†™ä¸€æ®µé€»è¾‘æ¥é‡æ’ selected åˆ—è¡¨
                # ä¾‹å¦‚: 
                # order_map = {"è‡ªç„¶èµ„æº":0, "æ½œåŠ›":1, "ç©ºé—´":2, "é—®é¢˜":3, "é¡¹ç›®":4}
                # selected.sort(key=lambda x: order_map.get(x.split('_')[1], 99))
                
                all_feature_names = []
                
                for f in selected:
                    path = os.path.join(DIRS["result"], f)
                    df = pd.read_csv(path)
                    
                    # å‡è®¾ç¬¬1åˆ—æ˜¯åœ°åŒº
                    region_col = df.columns[0]
                    df = df.set_index(region_col)
                    
                    # åªå–æ•°å€¼åˆ—
                    df_num = df.select_dtypes(include=['number']).fillna(0)
                    
                    matrices.append(df_num.values)
                    maps.append({name: i for i, name in enumerate(df_num.index)})
                    
                    # è®°å½•ç‰¹å¾å
                    feat_prefix = f.replace("parsed_", "").replace(".csv", "")
                    names.append(feat_prefix)
                    all_feature_names.extend([f"{feat_prefix}:{c}" for c in df_num.columns])
                
                # 1. èåˆ
                regions, X_final, slices = unify_and_concatenate(matrices, maps, names)
                
                if len(regions) > 0:
                    st.success(f"âœ… èåˆæˆåŠŸï¼åŸå§‹çŸ©é˜µå½¢çŠ¶: {X_final.shape} (åŒ…å« {len(regions)} ä¸ªåœ°åŒº)")
                    
                    # 2. å½’ä¸€åŒ–å¤„ç†
                    try:
                        st.info("æ­£åœ¨è¿›è¡Œ Min-Max å½’ä¸€åŒ–å¤„ç†...")
                        X_norm = preprocess_X(X_final)
                        
                        # 3. ä¿å­˜å½’ä¸€åŒ–åçš„çŸ©é˜µ
                        final_df = pd.DataFrame(X_norm, index=regions, columns=all_feature_names)
                        save_path = os.path.join(DIRS["4_results"], "parsed_final_matrix.csv")
                        final_df.to_csv(save_path, encoding='utf-8-sig')
                        
                        col1, col2 = st.columns([1, 1])
                        with col1:
                            st.write("ğŸ“Š **å½’ä¸€åŒ–åæ•°æ®é¢„è§ˆ:**")
                            st.dataframe(final_df.head(10))
                        
                        with col2:
                            st.write("ğŸ“¥ **ä¸‹è½½ç»“æœ:**")
                            st.download_button(
                                "ä¸‹è½½å½’ä¸€åŒ–çŸ©é˜µ (CSV)",
                                final_df.to_csv(encoding='utf-8-sig'),
                                "final_matrix_norm.csv",
                                "text/csv",
                                key='download-norm'
                            )
                            # ä¹Ÿå¯ä»¥æä¾›åŸå§‹çŸ©é˜µä¸‹è½½
                            raw_df = pd.DataFrame(X_final, index=regions, columns=all_feature_names)
                            st.download_button(
                                "ä¸‹è½½åŸå§‹çŸ©é˜µ (CSV)",
                                raw_df.to_csv(encoding='utf-8-sig'),
                                "final_matrix_raw.csv",
                                "text/csv",
                                key='download-raw'
                            )

                        # 4. çƒ­åŠ›å›¾å¯è§†åŒ–
                        st.divider()
                        st.subheader("ğŸ¨ ç‰¹å¾çƒ­åŠ›å›¾å¯è§†åŒ–")
                        
                        # æ£€æŸ¥æ˜¯å¦æœ‰ä¸­æ–‡å­—ä½“ï¼Œå¦‚æœæ²¡æœ‰å¯èƒ½æ˜¾ç¤ºæ–¹å—
                        # æˆ‘ä»¬å¯ä»¥ä¼ ç‰¹å¾åçš„ç´¢å¼•ï¼Œæˆ–è€…å°è¯•æ˜¾ç¤ºç‰¹å¾å
                        # ç”±äºç‰¹å¾åå¤ªé•¿ï¼Œå»ºè®®çƒ­åŠ›å›¾ x è½´åªæ˜¾ç¤ºç´¢å¼•
                        
                        fig = plot_heatmap(X_norm, regions) # ä¸ä¼  feature_namesï¼Œé»˜è®¤æ˜¾ç¤ºæ•°å­—ç´¢å¼•
                        st.pyplot(fig)
                        
                    except Exception as e:
                        st.error(f"å½’ä¸€åŒ–æˆ–ç»˜å›¾å¤±è´¥: {e}")
                        st.warning("å¯èƒ½æ˜¯çŸ©é˜µåˆ—æ•°ä¸ preprocess_X ä¸­ç¡¬ç¼–ç çš„ç´¢å¼•ä¸åŒ¹é…ã€‚è¯·æ£€æŸ¥ utils_fusion.pyã€‚")
                else:
                    st.error("èåˆå¤±è´¥ï¼šæ‰€é€‰æ•°æ®è¡¨ä¹‹é—´æ²¡æœ‰å…¬å…±åœ°åŒºã€‚")
            
# # ========================================================
if step == "5. æ•°æ®åˆ†ç±»ä¸å¯¼å‡º":
    st.header("ğŸ“Š æ­¥éª¤ 5: æ™ºèƒ½åˆ†åŒºåˆ†ç±» (K-Means)")
    
    auto_path = os.path.join(DIRS["4_results"], "parsed_final_matrix.csv")
    
    df_matrix = None
    if os.path.exists(auto_path):
        st.success("âœ… è‡ªåŠ¨æ£€æµ‹åˆ°æ­¥éª¤ 4 ç”Ÿæˆçš„çŸ©é˜µæ–‡ä»¶ã€‚")
        use_auto = st.checkbox("ä½¿ç”¨è‡ªåŠ¨ç”Ÿæˆçš„æ–‡ä»¶", value=True)
        if use_auto:
            df_matrix = pd.read_csv(auto_path, index_col=0)
    
    if df_matrix is None:
        uploaded_matrix = st.file_uploader("æˆ–è€…ä¸Šä¼ å·²æœ‰çš„çŸ©é˜µ CSV", type=["csv"])
        if uploaded_matrix:
            df_matrix = pd.read_csv(uploaded_matrix, index_col=0)

    data_source = st.radio("æ•°æ®æ¥æº", ["ä½¿ç”¨ä¸Šä¸€æ­¥èåˆçš„æ•°æ®", "ä¸Šä¼ å·²æœ‰çš„çŸ©é˜µ CSV"])
    df_matrix = None
    
    if data_source == "ä¸Šä¼ å·²æœ‰çš„çŸ©é˜µ CSV":
        uploaded_matrix = st.file_uploader("ä¸Šä¼ ç‰¹å¾çŸ©é˜µ CSV", type=["csv"])
        if uploaded_matrix:
            df_matrix = pd.read_csv(uploaded_matrix, index_col=0)
    else:
        # å°è¯•ä»å†…å­˜æˆ–ä¸´æ—¶æ–‡ä»¶è¯»å– (è¿™é‡Œå‡è®¾ Step 4 æä¾›äº†ä¸‹è½½ï¼Œæˆ‘ä»¬ä¹Ÿå¯ä»¥è®© Step 4 è‡ªåŠ¨å­˜ä¸€ä¸ªæ–‡ä»¶)
        # å»ºè®®åœ¨ Step 4 çš„ä»£ç æœ«å°¾åŠ ä¸€å¥: final_df.to_csv(os.path.join(DIRS["final"], "matrix_latest.csv"), ...)
        # è¿™é‡Œæ¨¡æ‹Ÿè¯»å–:
        auto_path = os.path.join(DIRS["4_results"], "parsed_final_matrix.csv") # å‡è®¾è·¯å¾„
        # ç”±äºStep 4åªæ˜¯æä¾›äº†ä¸‹è½½æŒ‰é’®ï¼Œä¸ºäº†è¿è´¯æ€§ï¼Œå»ºè®®ç”¨æˆ·æ‰‹åŠ¨ä¸Šä¼ åˆšæ‰ä¸‹è½½çš„æ–‡ä»¶ï¼Œæˆ–è€…æˆ‘ä»¬åœ¨Step 4å¢åŠ è‡ªåŠ¨ä¿å­˜é€»è¾‘
        # æš‚æ—¶æç¤ºç”¨æˆ·ä¸Šä¼ 
        st.info("è¯·ä¸Šä¼ æ­¥éª¤ 4 ä¸‹è½½çš„ `final_matrix.csv` æ–‡ä»¶è¿›è¡Œåˆ†æã€‚")
        uploaded_matrix = st.file_uploader("ä¸Šä¼  final_matrix.csv", type=["csv"], key="auto_upload")
        if uploaded_matrix:
            df_matrix = pd.read_csv(uploaded_matrix, index_col=0)

    if df_matrix is not None:
        st.write(f"âœ… å·²åŠ è½½æ•°æ®: {df_matrix.shape[0]} ä¸ªåœ°åŒº, {df_matrix.shape[1]} ä¸ªç‰¹å¾")
        st.dataframe(df_matrix.head(3))
        
        st.divider()
        
        # === å‚æ•°è®¾ç½®åŒºåŸŸ ===
        st.subheader("ğŸ› ï¸ æ¨¡å‹å‚æ•°é…ç½®")
        
        col1, col2 = st.columns([1, 2])
        
        with col1:
            n_clusters = st.slider("èšç±»ç±»åˆ«æ•°ç›® (K)", min_value=5, max_value=9, value=6)
            
        with col2:
            st.markdown("**âš–ï¸ æƒé‡è®¾å®š (ä¸“å®¶æ‰“åˆ†)**")
            
            # åŠ¨æ€ç”Ÿæˆæƒé‡è¾“å…¥æ¡†
            weight_settings = {}
            
            # ä½¿ç”¨ expander æ”¶çº³æƒé‡è®¾ç½®ï¼Œé¿å…ç•Œé¢å¤ªé•¿
            with st.expander("ç‚¹å‡»å±•å¼€è¯¦ç»†æƒé‡è®¾ç½®", expanded=True):
                # 1. è‡ªç„¶èµ„æº
                c1, c2 = st.columns(2)
                with c1:
                    w1 = st.number_input("1. è‡ªç„¶èµ„æºç¦€èµ‹ (æƒé‡)", value=5.0, step=0.1)
                    weight_settings["è‡ªç„¶èµ„æºç¦€èµ‹"] = w1
                with c2:
                    w1_bool = st.number_input("   â†³ æ—åœ°/å¸ƒå°”é¡¹ (æƒé‡)", value=1.0, step=0.1, help="weights_entory[3]")
                    weight_settings["è‡ªç„¶èµ„æº-å¸ƒå°”é¡¹"] = w1_bool
                
                # 2. æ½œåŠ›
                w2 = st.number_input("2. æ½œåŠ›é¡¹æ•°æ® (æƒé‡)", value=1.0, step=0.1)
                weight_settings["æ½œåŠ›é¡¹æ•°æ®"] = w2
                
                # 3. ç©ºé—´
                c3, c4 = st.columns(2)
                with c3:
                    w3 = st.number_input("3. ç©ºé—´å¸ƒå±€ (æƒé‡)", value=0.1, step=0.05)
                    weight_settings["ç©ºé—´å¸ƒå±€"] = w3
                with c4:
                    w4 = st.number_input("4. å­˜åœ¨é—®é¢˜ (æƒé‡)", value=0.1, step=0.05)
                    weight_settings["å­˜åœ¨é—®é¢˜"] = w4
                
                # 5. å­é¡¹ç›®
                w5 = st.number_input("5. å­é¡¹ç›®æ•°æ® (æƒé‡)", value=0.05, step=0.01)
                weight_settings["å­é¡¹ç›®æ•°æ®"] = w5

        # === æ‰§è¡Œåˆ†æ ===
        if st.button("ğŸš€ å¼€å§‹èšç±»åˆ†æ", type="primary"):
            try:
                # 1. æ„å»ºæƒé‡å‘é‡
                total_feats = df_matrix.shape[1]
                # å‡è®¾CSVçš„åˆ—é¡ºåºä¸¥æ ¼æŒ‰ç…§ FEATURE_GROUPS_DEF çš„é¡ºåºæ’åˆ—
                # å¦‚æœæ˜¯æ‚¨ä¹‹å‰æµç¨‹ç”Ÿæˆçš„çŸ©é˜µï¼Œé¡ºåºåº”è¯¥æ˜¯å¯¹çš„
                weights_vec = build_weight_vector(weight_settings, total_feats)
                
                # 2. æ‰§è¡Œèšç±»
                labels, X_pca, X_final = perform_clustering(df_matrix, n_clusters, weights_vec)
                
                # 3. ç»“æœå±•ç¤º
                df_matrix['Cluster_ID'] = labels
                df_matrix['Cluster_Label'] = df_matrix['Cluster_ID'].apply(lambda x: f"ç±»åˆ« {x+1}")
                
                st.success("âœ… èšç±»å®Œæˆï¼")
                
                # å¯è§†åŒ–
                st.subheader("ğŸ“ˆ èšç±»ç»“æœå¯è§†åŒ– (PCA)")
                fig = plot_clusters(X_pca, labels, df_matrix.index)
                st.pyplot(fig)
                
                # ç»“æœè¡¨æ ¼
                st.subheader("ğŸ“‹ åˆ†ç±»ç»“æœè¡¨")
                st.dataframe(df_matrix[['Cluster_Label']].sort_values('Cluster_Label'))
                
                # ä¸‹è½½
                csv = df_matrix.to_csv(encoding='utf-8-sig')
                st.download_button(
                    "ğŸ“¥ ä¸‹è½½å¸¦åˆ†ç±»ç»“æœçš„ CSV",
                    csv,
                    "clustered_result.csv",
                    "text/csv"
                )
                
            except Exception as e:
                st.error(f"åˆ†æå‡ºé”™: {e}")
                st.warning("æç¤ºï¼šè¯·ç¡®ä¿è¾“å…¥çš„çŸ©é˜µåˆ—é¡ºåºä¸é¢„è®¾çš„ç‰¹å¾ç»„é¡ºåºä¸€è‡´ã€‚")