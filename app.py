import streamlit as st
import os
import pandas as pd
import time
import json
import zipfile
import shutil
from utils_pdf import extract_section_to_pdf, extract_section_to_pdf_self, \
    extract_info,parser_file,extract_pages_by_keywords,dict_save2csv
from api_client import CozeClient, get_mock_data, WORKFLOW_CONFIG 
from utils_fusion import unify_and_concatenate, preprocess_X # å¼•å…¥å½’ä¸€åŒ–å‡½æ•°
from utils_vis import plot_heatmap # å¼•å…¥å¯è§†åŒ–
from utils_parse import process_raw_data

# from utils_parsers import process_raw_data
# from utils_fusion import unify_and_concatenate

# === é¡µé¢é…ç½® ===
st.set_page_config(page_title="åœŸåœ°æ•´æ²»æ™ºèƒ½åˆ†æå¹³å°", layout="wide")
st.title("ğŸ—ï¸ åœŸåœ°æ•´æ²»æ–‡æ¡£æ™ºèƒ½åˆ†ç±»ç³»ç»Ÿ")

# === ä¸´æ—¶æ–‡ä»¶ç®¡ç† ===
TEMP_DIR = "temp_workspace"
DIRS = {
    "upload": os.path.join(TEMP_DIR, "1_uploads"),
    "crop": os.path.join(TEMP_DIR, "2_cropped"),
    "raw": os.path.join(TEMP_DIR, "3_raw_data"),
    "result": os.path.join(TEMP_DIR, "4_results"), 
    "final": os.path.join(TEMP_DIR, "5_final")
}
TEMPLATE_COLUMNS = {
    "spatial": ["åœ°åŒº", "æ°¸å†œè°ƒå…¥è§„æ¨¡ï¼ˆå…¬é¡·ï¼‰", "æ°¸å†œè°ƒå‡ºè§„æ¨¡ï¼ˆå…¬é¡·ï¼‰", "åŸé•‡å¼€å‘è°ƒå…¥è§„æ¨¡ï¼ˆå…¬é¡·ï¼‰", "åŸé•‡å¼€å‘è°ƒå‡ºè§„æ¨¡ï¼ˆå…¬é¡·ï¼‰", "è§„åˆ’å•å…ƒç©ºé—´è°ƒæ•´æ‰“åˆ†ï¼ˆæœ€é«˜5åˆ†ï¼‰"],
    "potential": ["åœ°åŒº", "å¦é€ æ°´ç”°æ½œåŠ›", "æ–°å¢è€•åœ°æ½œåŠ›", "è€•åœ°æ¢å¤æ½œåŠ›", "é«˜æ ‡å‡†å†œç”°å»ºè®¾æ½œåŠ›", "çŸ¿å±±ä¿®å¤æ½œåŠ›", "çº¢æ ‘æ—ä¿æŠ¤æ½œåŠ›"],
    "issue": ["åœ°åŒº", "è€•åœ°ç¢ç‰‡åŒ–_æ’åº", "è€•åœ°ç¢ç‰‡åŒ–_è¯´æ˜", "ä½æ•ˆç”¨åœ°é—®é¢˜_æ’åº", "ä½æ•ˆç”¨åœ°é—®é¢˜_è¯´æ˜"],
    "landuse": ["åœ°åŒº", "å†œç”¨åœ°", "å»ºè®¾ç”¨åœ°", "ç”Ÿæ€ä¿æŠ¤", "æ—åœ°å æ¯”"],
    "project": ["åœ°åŒº", "å†œç”¨åœ°æ•´ç†ç±»é¡¹ç›®_æ•°é‡", "å†œç”¨åœ°æ•´ç†ç±»é¡¹ç›®_æŠ•èµ„", "å†œç”¨åœ°æ•´ç†ç±»é¡¹ç›®_è§„æ¨¡"],
    "default": ["åœ°åŒº", "æŒ‡æ ‡1", "æŒ‡æ ‡2", "æŒ‡æ ‡3"]
}

# åˆå§‹åŒ–ç›®å½•
for d in DIRS.values():
    if not os.path.exists(d): os.makedirs(d)

# === ä¾§è¾¹æ ï¼šæµç¨‹æ§åˆ¶ ===
with st.sidebar:
    st.header("å·¥ä½œæµå¯¼èˆª")
    step = st.radio("é€‰æ‹©æ­¥éª¤", [
        "1. æ–‡æ¡£ä¸Šä¼ ä¸è£å‰ª", 
        "2. å¤§æ¨¡å‹æ•°æ®è·å–", 
        "3. æ•°æ®è§£æ", 
        "4. æ•°æ®èåˆ&å±•ç¤º",
        "5. æ•°æ®åˆ†ç±»ä¸å¯¼å‡º"
    ])
    
    st.divider()
    if st.button("æ¸…ç†ä¸´æ—¶æ–‡ä»¶"):
        if os.path.exists(TEMP_DIR):
            shutil.rmtree(TEMP_DIR)
            for d in DIRS.values():
                if not os.path.exists(d): os.makedirs(d)
        st.success("å·²æ¸…ç†ç¼“å­˜")

# å®šä¹‰å…¨å±€ä»»åŠ¡å­—å…¸
TASK_DICT={
    "è‡ªç„¶èµ„æºç¦€èµ‹":"landuse",
    "å­˜åœ¨é—®é¢˜":"issue",
    "æ•´æ²»æ½œåŠ›":"potential",
    "å­é¡¹ç›®":"project",
    "ç©ºé—´å¸ƒå±€":"spatial"
}

def render_file_manager(dir_path, title="ç»“æœæ–‡ä»¶ç®¡ç†", file_ext=".csv", key_prefix="common"):
    """
    é€šç”¨æ–‡ä»¶ç®¡ç†ç»„ä»¶ï¼šåˆ—è¡¨ã€é¢„è§ˆã€ä¸‹è½½ã€åˆ é™¤
    """
    st.divider()
    st.subheader(f"ğŸ“‚ {title}")
    
    if not os.path.exists(dir_path):
        st.info("æš‚æ— æ–‡ä»¶ç”Ÿæˆã€‚")
        return
    # scan files
    files = [f for f in os.listdir(dir_path) if f.endswith(file_ext)]
    files.sort(key=lambda x: os.path.getmtime(os.path.join(dir_path, x)), reverse=True) # æŒ‰æ—¶é—´å€’åº

    if files:
        # 1. file table display
        df_files = pd.DataFrame(files, columns=["æ–‡ä»¶å"])
        st.dataframe(df_files, use_container_width=True, height=150)
        
        # 2. file delete
        with st.expander("ğŸ—‘ï¸ ç®¡ç†/åˆ é™¤æ–‡ä»¶"):
            files_to_del = st.multiselect("é€‰æ‹©è¦åˆ é™¤çš„æ–‡ä»¶", files, key=f"{key_prefix}_del_multi")
            if st.button("ç¡®è®¤åˆ é™¤", key=f"{key_prefix}_del_btn"):
                for f in files_to_del:
                    try: os.remove(os.path.join(dir_path, f))
                    except: pass
                st.success(f"å·²åˆ é™¤ {len(files_to_del)} ä¸ªæ–‡ä»¶")
                time.sleep(1)
                st.rerun()

        # 3. preview & single download
        c1, c2 = st.columns([2, 1])
        with c1:
            sel_file = st.selectbox("é€‰æ‹©æ–‡ä»¶é¢„è§ˆ:", files, key=f"{key_prefix}_sel")
            if sel_file:
                file_path = os.path.join(dir_path, sel_file)
                if file_ext == ".csv":
                    try:
                        try: df = pd.read_csv(file_path)
                        except: df = pd.read_csv(file_path, encoding='gbk')
                        st.write(f"ğŸ“Š `{sel_file}` :")
                        st.dataframe(df.head())
                    except Exception as e:
                        st.error(f"è¯»å–å¤±è´¥: {e}")
                elif file_ext == ".pdf":
                    st.caption("PDF æ–‡ä»¶ä¸æ”¯æŒç›´æ¥é¢„è§ˆï¼Œè¯·ä¸‹è½½æŸ¥çœ‹ã€‚")
        with c2:
            if sel_file:
                file_path = os.path.join(dir_path, sel_file)
                with open(file_path, "rb") as f:
                    mime_type = "text/csv" if file_ext == ".csv" else "application/pdf"
                    st.download_button(
                        label=f"ğŸ“¥ ä¸‹è½½ {sel_file}",
                        data=f,
                        file_name=sel_file,
                        mime=mime_type,
                        key=f"{key_prefix}_down_btn",
                        type="primary"
                    )           
        # 4. package download
        zip_name = f"all_{key_prefix}_files.zip"
        zip_path = os.path.join(TEMP_DIR, zip_name)
        with zipfile.ZipFile(zip_path, 'w') as zf:
            for f in files:
                zf.write(os.path.join(dir_path, f), f)
        with open(zip_path, "rb") as f:
            st.download_button(f"ğŸ“¦ æ‰“åŒ…ä¸‹è½½å…¨éƒ¨ ({len(files)}ä¸ª)", f, zip_name, "application/zip", key=f"{key_prefix}_zip")        
    else:
        st.info(f"å½“å‰ä»»åŠ¡çš„ç›®å½•ä¸ºç©º ({dir_path})")
# ========================================================
# 1. ä¸Šä¼ ä¸è£å‰ª
# ========================================================
if step == "1. æ–‡æ¡£ä¸Šä¼ ä¸è£å‰ª":
    st.header("ğŸ“„ æ­¥éª¤ 1: PDF æ–‡æ¡£å¤„ç†")
    
    tab1, tab2 = st.tabs(["ğŸš€ æ‰¹é‡è‡ªåŠ¨è£å‰ª", "ğŸ› ï¸ æ‰‹åŠ¨è£å‰ªä¿®å¤"])
    
    # --- Tab 1: è‡ªåŠ¨è£å‰ª ---
    with tab1:
        st.markdown("ä¸Šä¼ åŸå§‹æ–‡æ¡£ï¼Œç³»ç»Ÿå°†æ ¹æ®æå–æ¨¡å¼è‡ªåŠ¨è£å‰ªå‡ºå…³é”®é¡µé¢ã€‚")
        uploaded_files = st.file_uploader("ä¸Šä¼  PDF æ–‡ä»¶", type=["pdf"], accept_multiple_files=True, key="auto_uploader")
        
        col1, col2 = st.columns([1, 1])
        with col1:
            # === ä¿®æ”¹ç‚¹ï¼šåŸºäºä¸šåŠ¡åœºæ™¯çš„é€‰æ‹© ===
            crop_task_type = st.selectbox(
                "é€‰æ‹©è¦æå–çš„æ•°æ®ç±»å‹", 
                list(TASK_DICT.keys()) + ["è‡ªå®šä¹‰ç›®å½•åŒ¹é…", "è‡ªå®šä¹‰å…¨æ–‡æœç´¢"])
        with col2:
            # === æ ¸å¿ƒé€»è¾‘ï¼šæ ¹æ®é€‰æ‹©è‡ªåŠ¨é¢„è®¾å‚æ•° ===
            default_kw = ""
            algo_type = "TOC" # é»˜è®¤ç›®å½•åŒ¹é…
            
            if "è‡ªç„¶èµ„æºç¦€èµ‹" in crop_task_type:
                default_kw = r"(åœŸåœ°åˆ©ç”¨.*è¡¨|è¡¨.*åœŸåœ°åˆ©ç”¨.*è¡¨)"
                algo_type = "Content" # å…¨æ–‡æ‰«æ
            elif "å­˜åœ¨é—®é¢˜" in crop_task_type:
                default_kw = "å­˜åœ¨é—®é¢˜"
            elif "æ•´æ²»æ½œåŠ›" in crop_task_type:
                default_kw = "æ•´æ²»å¯è¡Œæ€§åˆ†æ"
            elif "å­é¡¹ç›®" in crop_task_type:
                default_kw = "å­é¡¹ç›®å®‰æ’" # æˆ–è€…æ˜¯ "é¡¹ç›®"
            elif "ç©ºé—´å¸ƒå±€" in crop_task_type:
                default_kw = "ç©ºé—´å¸ƒå±€ä¼˜åŒ–"
            # å…è®¸ç”¨æˆ·å¾®è°ƒå…³é”®è¯
            keyword = st.text_input("æå–å…³é”®è¯ (æ”¯æŒæ­£åˆ™)", value=default_kw)
            
            # æ˜¾ç¤ºå½“å‰ä½¿ç”¨çš„ç®—æ³•æç¤º
            if algo_type == "Content" or crop_task_type == "è‡ªå®šä¹‰å…¨æ–‡æœç´¢":
                st.caption("â„¹ï¸ æ¨¡å¼ï¼š**å…¨æ–‡å…³é”®è¯æ‰«æ** (é€‚åˆè·¨é¡µå¤§è¡¨)")
                use_content_mode = True
            else:
                st.caption("â„¹ï¸ æ¨¡å¼ï¼š**ç›®å½•ç« èŠ‚åŒ¹é…** (é€‚åˆæ ‡å‡†æ–‡æœ¬ç« èŠ‚)")
                use_content_mode = False
        
        if st.button("å¼€å§‹è‡ªåŠ¨è£å‰ª", type="primary"):
            if not uploaded_files:
                st.error("è¯·å…ˆä¸Šä¼ æ–‡ä»¶ï¼")
            else:
                bar = st.progress(0)
                status = st.empty()
                success_count = 0
                for i, f in enumerate(uploaded_files):
                    src_path = os.path.join(DIRS["upload"], f.name)
                    with open(src_path, "wb") as buffer: buffer.write(f.getbuffer())
                    status.text(f"æ­£åœ¨å¤„ç†: {f.name}...")
                    
                    # 1. æå–ä¿¡æ¯
                    info = extract_info(f.name)
                    clean_region_name = info["æ–‡ä»¶å"]
                    
                    # 2. æ„é€ æ–°æ–‡ä»¶å (å¸¦ä¸Šä»»åŠ¡ç±»å‹æ ‡è¯†ï¼Œæ–¹ä¾¿åç»­è¯†åˆ«)
                    # ç®€åŒ–åç¼€ï¼šè‡ªç„¶èµ„æºç¦€èµ‹ -> landuse, å­˜åœ¨é—®é¢˜ -> issue ç­‰
                    task_suffix = "data"
                    if crop_task_type in TASK_DICT:
                        task_suffix = TASK_DICT[crop_task_type]
                    else:
                        task_suffix = keyword.replace("*", "")[:5]

                    dst_name = f"{clean_region_name}_{task_suffix}.pdf"
                    dst_path = os.path.join(DIRS["crop"], dst_name)
                    
                    # 3. æ‰§è¡Œè£å‰ª (æ ¹æ®æ¨¡å¼é€‰æ‹©å‡½æ•°)
                    is_ok = False
                    
                    if use_content_mode:
                        # å…¨æ–‡æ‰«ææ¨¡å¼ (ç”¨äºè‡ªç„¶èµ„æº/åœŸåœ°åˆ©ç”¨è¡¨)
                        is_ok = extract_pages_by_keywords(src_path, dst_path, keyword)
                    else:
                        # ç›®å½•åŒ¹é…æ¨¡å¼ (ç”¨äºå…¶ä»–)
                        is_ok = extract_section_to_pdf(src_path, dst_path, keyword)
                    
                    if is_ok: 
                        success_count += 1
                    
                    bar.progress((i + 1) / len(uploaded_files))
                
                if success_count == len(uploaded_files): 
                    st.success(f"âœ… å…¨éƒ¨å¤„ç†å®Œæˆï¼æˆåŠŸ {success_count} ä¸ªã€‚")
                else: 
                    st.warning(f"âš ï¸ æˆåŠŸ {success_count} ä¸ªï¼Œå¤±è´¥ {len(uploaded_files)-success_count} ä¸ªã€‚å»ºè®®å°è¯•æ‰‹åŠ¨ä¿®å¤å¤±è´¥çš„æ–‡ä»¶ã€‚")

    # --- Tab 2: æ‰‹åŠ¨è£å‰ª ---
    with tab2:
        st.info("è‡ªåŠ¨è£å‰ªå¤±è´¥æˆ–è£å‰ªå†…å®¹æœ‰è¯¯ï¼Œè¯·åœ¨æ­¤å¤„æ‰‹åŠ¨æŒ‡å®šé¡µç ã€‚**ç³»ç»Ÿä¼šè‡ªåŠ¨è¦†ç›–åŒåçš„æ—§æ–‡ä»¶**ï¼Œç¡®ä¿åç»­æµç¨‹é¡ºåˆ©è¿è¡Œã€‚")
        # 1. choose file to crop
        existing_files = [f for f in os.listdir(DIRS["upload"]) if f.endswith(".pdf")]
        col_up, col_sel = st.columns([1, 2])
        with col_up: manual_file = st.file_uploader("ä¸Šä¼ å•ä¸ªæ–‡ä»¶", type=["pdf"], key="manual_uploader")
        target_file_path = None
        if manual_file:
            target_file_path = os.path.join(DIRS["upload"], manual_file.name)
            with open(target_file_path, "wb") as f: f.write(manual_file.getbuffer())
            st.info(f"å·²é€‰ä¸­: {manual_file.name}")
        elif existing_files:
            sel = col_sel.selectbox("é€‰æ‹©å·²ä¸Šä¼ æ–‡ä»¶", existing_files)
            if sel: target_file_path = os.path.join(DIRS["upload"], sel)
        
        if target_file_path:
            st.divider()
            c1, c2 = st.columns(2)

            with c1:
                manual_task_type = st.selectbox(
                    "è¿™æ˜¯å“ªç±»æ•°æ®çš„æ–‡æ¡£ï¼Ÿ", 
                    list(TASK_DICT.keys()), 
                    key="manual_task_sel",
                    help="é€‰æ‹©æ­£ç¡®çš„ç±»å‹ï¼Œç³»ç»Ÿå°†è‡ªåŠ¨ç”Ÿæˆæ ‡å‡†æ–‡ä»¶åï¼ˆå¦‚ _landuse.pdfï¼‰ï¼Œè¦†ç›–ä¹‹å‰è‡ªåŠ¨ç”Ÿæˆçš„é”™è¯¯æ–‡ä»¶ã€‚"
                )
            # split pages
            with c2:
                col_p1, col_p2 = st.columns(2)
                with col_p1: start_p = st.number_input("èµ·å§‹é¡µç ", min_value=1, value=1)
                with col_p2: end_p = st.number_input("ç»“æŸé¡µç ", min_value=1, value=5)
            
            if st.button("âœ‚ï¸ æ‰§è¡Œè£å‰ªå¹¶è¦†ç›–", type="primary"):
                if end_p <= start_p: 
                    st.error("ç»“æŸé¡µç å¿…é¡»å¤§äºèµ·å§‹é¡µç ï¼")
                else:
                    f_name = os.path.basename(target_file_path)
                    info = extract_info(f_name)
                    
                    # === å…³é”®ï¼šä½¿ç”¨æ ‡å‡†åç¼€ç”Ÿæˆæ–‡ä»¶å ===
                    task_suffix = TASK_DICT[manual_task_type]
                    # ç”Ÿæˆå¦‚ "ä¸œè-å‡¤å²—_landuse.pdf"
                    dst_name = f"{info['æ–‡ä»¶å']}_{task_suffix}.pdf"
                    dst_path = os.path.join(DIRS["crop"], dst_name)
                    # check file replace
                    if os.path.exists(dst_path):
                        st.info(f"ğŸ”„ æ£€æµ‹åˆ°æ—§æ–‡ä»¶ `{dst_name}`ï¼Œå°†è¢«æ–°è£å‰ªçš„æ–‡ä»¶è¦†ç›–ã€‚")
                    if extract_section_to_pdf_self(target_file_path, start_p, end_p, dst_path):
                        st.success(f"âœ… ä¿®å¤æˆåŠŸï¼æ–‡ä»¶å·²ä¿å­˜ä¸º: `{dst_name}`")
                        # ç¨å¾®å»¶è¿Ÿååˆ·æ–°ï¼Œè®©æ–‡ä»¶åˆ—è¡¨æ›´æ–°
                        time.sleep(1)
                        st.rerun() 
                    else: 
                        st.error("âŒ è£å‰ªå¤±è´¥ï¼Œè¯·æ£€æŸ¥PDFæ˜¯å¦æŸåæˆ–é¡µç è¶Šç•Œã€‚")
    st.divider()
    st.subheader("ğŸ“‚ ç»“æœæ–‡ä»¶ç®¡ç†")
    
    cropped_files = []
    if os.path.exists(DIRS["crop"]):
        cropped_files = [f for f in os.listdir(DIRS["crop"]) if f.endswith(".pdf")]
    
    if cropped_files:
        # 1. åˆ—è¡¨å±•ç¤º
        st.dataframe(pd.DataFrame(cropped_files, columns=["å·²ç”Ÿæˆçš„æ–‡ä»¶å"]), use_container_width=True, height=200)
        
        with st.expander("ğŸ—‘ï¸ ç®¡ç†/åˆ é™¤å·²å¤„ç†æ–‡ä»¶"):
            files_to_delete = st.multiselect("é€‰æ‹©è¦åˆ é™¤çš„æ–‡ä»¶ (æ”¯æŒå¤šé€‰)", cropped_files)
            if st.button("ç¡®è®¤åˆ é™¤é€‰ä¸­æ–‡ä»¶"):
                if files_to_delete:
                    for f_del in files_to_delete:
                        path_to_del = os.path.join(DIRS["crop"], f_del)
                        try:
                            os.remove(path_to_del)
                        except Exception as e:
                            st.error(f"åˆ é™¤å¤±è´¥ {f_del}: {e}")
                    st.success(f"å·²åˆ é™¤ {len(files_to_delete)} ä¸ªæ–‡ä»¶")
                    time.sleep(1)
                    st.rerun()
                else:
                    st.warning("è¯·å…ˆé€‰æ‹©è¦åˆ é™¤çš„æ–‡ä»¶")
        col_d1, col_d2 = st.columns(2)
        
        # 2. æ‰¹é‡æ‰“åŒ…ä¸‹è½½åŠŸèƒ½
        with col_d1:
            zip_path = os.path.join(TEMP_DIR, "cropped_files.zip")
            with zipfile.ZipFile(zip_path, 'w') as zipf:
                for f in cropped_files:
                    zipf.write(os.path.join(DIRS["crop"], f), f)
            
            with open(zip_path, "rb") as f:
                st.download_button(
                    label="ğŸ“¦ æ‰“åŒ…ä¸‹è½½æ‰€æœ‰æ–‡ä»¶ (.zip)",
                    data=f,
                    file_name="cropped_files.zip",
                    mime="application/zip",
                    type="primary"
                )
        
        # 3. å•æ–‡ä»¶ä¸‹è½½åŠŸèƒ½
        with col_d2:
            selected_download = st.selectbox("æˆ–è€…é€‰æ‹©å•ä¸ªæ–‡ä»¶ä¸‹è½½:", cropped_files)
            if selected_download:
                file_path = os.path.join(DIRS["crop"], selected_download)
                with open(file_path, "rb") as f:
                    st.download_button(
                        label=f"ğŸ“„ ä¸‹è½½ {selected_download}",
                        data=f,
                        file_name=selected_download,
                        mime="application/pdf"
                    )
    else:
        st.info("æš‚æ— å¤„ç†å¥½çš„æ–‡ä»¶ï¼Œè¯·å…ˆæ‰§è¡Œè£å‰ªæ“ä½œã€‚")
# ========================================================
# 2. æ•°æ®æå– (API)
# ========================================================
elif step == "2. å¤§æ¨¡å‹æ•°æ®è·å–":
    st.header("ğŸ¤– æ­¥éª¤ 2: è°ƒç”¨å¤§æ¨¡å‹æ™ºèƒ½ä½“è·å–æ•°æ®")
    # 1. æ‰«ææ–‡ä»¶
    files = [f for f in os.listdir(DIRS["crop"]) if f.endswith(".pdf")]    
    if not files:
        st.warning("âš ï¸ æš‚æ— å·²è£å‰ªæ–‡ä»¶ï¼Œè¯·å…ˆå®Œæˆæ­¥éª¤ 1ã€‚")
    else:
        # 2. æ–‡ä»¶åæ¸…æ´—é¢„è§ˆ
        st.subheader("1ï¸âƒ£ æ–‡ä»¶åæ¸…æ´—ä¸åœ°åŒºè¯†åˆ«")
        file_info_list = []
        for f in files:
            info = parser_file(f) # è°ƒç”¨ utils_pdf ä¸­çš„æ–°å‡½æ•°
            file_info_list.append(info)
        
        info_df = pd.DataFrame(file_info_list)
        st.dataframe(info_df[["æ–‡ä»¶å", "åŸå¸‚", "åœ°åŒº/å¿","è¯¦ç»†å•å…ƒ"]], use_container_width=True)

        st.divider()
        
        # 3. ä»»åŠ¡é…ç½®
        st.subheader("2ï¸âƒ£ å¼€å§‹æå–")
        col1, col2 = st.columns([1, 1])
        with col1:
            task_type = st.selectbox("é€‰æ‹©åˆ†æä»»åŠ¡ç±»å‹", list(TASK_DICT.keys()))
        with col2:
            use_mock = st.checkbox("ä½¿ç”¨æ¨¡æ‹Ÿæ•°æ® (è°ƒè¯•ç”¨)", value=True)
            
        if st.button("ğŸš€ å¤§æ¨¡å‹åˆ†æ", type="primary"):
            results = []
            progress_bar = st.progress(0)
            log_container = st.container() # ç”¨äºæ˜¾ç¤ºå®æ—¶æ—¥å¿—
            
            # åˆå§‹åŒ–å®¢æˆ·ç«¯
            client = None
            if not use_mock:
                client = CozeClient() 
                workflow_id = WORKFLOW_CONFIG.get(task_type)
            # å¼€å§‹å¾ªç¯å¤„ç†
            for i, info in enumerate(file_info_list):
                file_name = info["åŸå§‹æ–‡ä»¶å"]
                # è¿™é‡Œçš„â€œæ–°æ–‡ä»¶åâ€å®é™…ä¸Šå°±æ˜¯æ­¥éª¤1ç”Ÿæˆçš„è§„èŒƒåŒ–æ–‡ä»¶å (ä¾‹å¦‚: æ½®å·-æ¹˜æ¡¥_é—®é¢˜)

                region_name = info["æ–‡ä»¶å"] 
                
                file_path = os.path.join(DIRS["crop"], file_name)
                
                # --- UI æ˜¾ç¤ºå½“å‰çŠ¶æ€ ---
                with log_container:
                    status_expander = st.expander(f"ğŸ”„ æ­£åœ¨å¤„ç†: {region_name} ...", expanded=True)
                    with status_expander:
                        st.write(f"ğŸ“„ æ–‡ä»¶: `{file_name}`")
                        # --- è°ƒç”¨ API ---
                        raw_data = None
                        try:
                            if use_mock:
                                time.sleep(0.5)
                                raw_data = get_mock_data(file_path, task_type)
                                st.info("âœ… æ¨¡æ‹Ÿæ•°æ®è·å–æˆåŠŸ")
                            else:
                                st.write("ğŸ“¤ ä¸Šä¼ æ–‡ä»¶ä¸­...")
                                file_id = client.upload_file(file_path)
                                if file_id:
                                    st.write("ğŸ¤– AI æ€è€ƒä¸­...")
                                    raw_data = client.run_workflow(workflow_id, file_id)
                                    if raw_data:
                                        st.success("âœ… å·¥ä½œæµæ‰§è¡ŒæˆåŠŸ")
                                    else:
                                        st.error("âŒ å·¥ä½œæµè¿”å›ä¸ºç©º")
                                else:
                                    st.error("âŒ ä¸Šä¼ å¤±è´¥")
                                time.sleep(1) # é™æµä¿æŠ¤
                        except Exception as e:
                            st.error(f"âŒ å‘ç”Ÿå¼‚å¸¸: {e}")
                        # --- æ˜¾ç¤ºè¾“å‡ºå†…å®¹ ---
                        if raw_data:
                            st.markdown("**ğŸ” è¾“å‡ºå†…å®¹é¢„è§ˆ:**")
                            try:
                                json_data = json.loads(raw_data)
                                st.json(json_data)
                                if "output" in json_data:
                                    st.text_area("è§£ææ–‡æœ¬", json_data["output"], height=200)
                            except:
                                st.text(raw_data)
                            # ä¿å­˜ç»“æœ
                            results.append({
                                "åœ°åŒº": region_name,
                                "rawdata": raw_data,
                            })
                # æ›´æ–°æ€»è¿›åº¦
                progress_bar.progress((i + 1) / len(files))
            
            # å¾ªç¯ç»“æŸ
            st.success(f"ğŸ‰ æ‰€æœ‰æ–‡ä»¶å¤„ç†å®Œæˆï¼æˆåŠŸè·å– {len(results)} æ¡æ•°æ®ã€‚")
            
            # ä¿å­˜åˆ° CSV
            if results:
                df_result = pd.DataFrame(results)
                task_suffix = TASK_DICT[task_type]
                save_filename = f"coze_raw_output_{task_suffix}.csv"
                save_path = os.path.join(DIRS["raw"], save_filename)
                
                df_result.to_csv(save_path, index=False, encoding='utf-8-sig')
                st.write(f"æ•°æ®å·²ä¿å­˜è‡³: `{save_path}`")
                st.dataframe(df_result.head())
            
    # ä¿å­˜æ–‡ä»¶å¯è§†åŒ– & ä¸‹è½½
    st.divider()
    st.subheader("ğŸ“‚ ç»“æœæ–‡ä»¶ç®¡ç†")
    coze_files = []
    if os.path.exists(DIRS["raw"]):
        coze_files = [f for f in os.listdir(DIRS["raw"]) if f.endswith(".csv")]
    if coze_files:
        # 2. file list display
        st.dataframe(pd.DataFrame(coze_files, columns=["å¤§æ¨¡å‹è§£æç”Ÿæˆçš„æ•°æ®æ–‡ä»¶"]), use_container_width=True)
        
        col_preview, col_down = st.columns([2, 1])
        with col_preview:
            # 3. file preview
            selected_preview = st.selectbox("é€‰æ‹©æ–‡ä»¶è¿›è¡Œé¢„è§ˆ:", coze_files, key="preview_sel")
            if selected_preview:
                preview_path = os.path.join(DIRS["raw"], selected_preview)
                try:
                    pre_df = pd.read_csv(preview_path)
                    st.write(f"ğŸ“Š `{selected_preview}` æ•°æ®é¢„è§ˆ (å‰ 5 è¡Œ):")
                    st.dataframe(pre_df.head())
                except Exception as e:
                    st.error(f"è¯»å–å¤±è´¥: {e}")
        with col_down:
            # 4. download 
            if selected_preview:
                preview_path = os.path.join(DIRS["raw"], selected_preview)
                with open(preview_path, "rb") as f:
                    st.download_button(
                        label=f"ğŸ“¥ ä¸‹è½½ {selected_preview}",
                        data=f,
                        file_name=selected_preview,
                        mime="text/csv",
                        type="primary"
                    )
    else:
        st.info("æš‚æ— ç”Ÿæˆçš„åŸå§‹æ•°æ®æ–‡ä»¶ã€‚")        
# # ========================================================
# # 3. æ•°æ®è§£æ
# # ========================================================
elif step == "3. æ•°æ®è§£æ":
    st.header("ğŸ§¹ æ­¥éª¤ 3: ç»“æ„åŒ–è§£æ")
    # === ä½¿ç”¨ Tabs åˆ†æµï¼šæ­£å¸¸è§£æ vs æ‰‹åŠ¨ä¸Šä¼  ===
    tab1, tab2 = st.tabs(["âš™ï¸ è§£æåŸå§‹æ•°æ®", "ğŸ“¤ ä¸Šä¼ å¤–éƒ¨æ•°æ® (è¡¥å……ç¼ºå¤±é¡¹)"])
    
    # æ­£å¸¸æ•°æ®è§£æ
    with tab1:
        col1, col2 = st.columns([1, 1])
        with col1:
            parse_type = st.selectbox("é€‰æ‹©è§£ææ¨¡å¼", list(TASK_DICT.keys()))
        task_suffix = TASK_DICT[parse_type]
        raw_filename = f"coze_raw_output_{task_suffix}.csv"
        raw_file = os.path.join(DIRS["raw"], raw_filename)
        
        if not os.path.exists(raw_file):
            st.warning(f"âš ï¸ æœªæ‰¾åˆ°å¯¹åº”çš„æ•°æ®æ–‡ä»¶ï¼š{raw_filename}ã€‚è¯·å…ˆå®Œæˆæ­¥éª¤ 2 ä¸­è¯¥ç±»å‹çš„æå–ã€‚")
        else:
            df_raw = pd.read_csv(raw_file)
            st.write(f"ğŸ“‚ è¯»å–æ•°æ®æº: `{raw_filename}`")
            st.write("åŸå§‹æ•°æ®é¢„è§ˆ:", df_raw.head(3))
            
            if col2.button("æ•°æ®è§£æ", type="primary"):
                # 1. è°ƒç”¨ utils_parsers ä¸­çš„å¤„ç†å‡½æ•°
                # process_raw_data ä¼šè¿”å›çº¯ç‰¹å¾æ•°æ®çš„ DataFrame (ä¸å«åœ°åŒºåˆ—)
                parsed_df = process_raw_data(df_raw, parse_type)
                
                # 2. åˆå¹¶åœ°åŒºåˆ— (ç¡®ä¿æ•°æ®å¯¹é½)
                # å…³é”®ï¼šç¡®ä¿ parsed_df çš„ç´¢å¼•ä¸ df_raw ä¸€è‡´ï¼Œé˜²æ­¢é”™ä½
                parsed_df.index = df_raw.index 
                
                # ä½¿ç”¨ join æˆ–è€… concat (axis=1)
                # åªå– 'åœ°åŒº' åˆ—å’Œæ–°ç”Ÿæˆçš„ç‰¹å¾åˆ—
                final_df = pd.concat([df_raw[['åœ°åŒº']], parsed_df], axis=1)
                
                # 3. æ„é€ è¾“å‡ºæ–‡ä»¶å (parsed_landuse.csv, parsed_issue.csv ...)
                out_name = f"parsed_{task_suffix}.csv"
                save_path = os.path.join(DIRS["result"], out_name)
                
                # 4. ä¿å­˜
                final_df.to_csv(save_path, index=False, encoding='utf-8-sig')
                
                st.success(f"âœ… è§£ææˆåŠŸï¼ç»“æœå·²ä¿å­˜è‡³: {out_name}")
                st.dataframe(final_df.head())
    # æ‰‹åŠ¨ä¸Šä¼ å¤–éƒ¨æ•°æ®
    with tab2:
        st.markdown("""
        **åŠŸèƒ½è¯´æ˜ï¼š** å¦‚æœæŸäº›æ•°æ®ï¼ˆå¦‚ç©ºé—´å¸ƒå±€è§„åˆ’ï¼‰æ— æ³•é€šè¿‡ `PDF` æå–ï¼Œæˆ–è€…æ‚¨å·²ç»æœ‰æ•´ç†å¥½çš„ `Excel/CSV `æ•°æ®ï¼Œåœ¨æ­¤å¤„ä¸Šä¼ ã€‚
        ç³»ç»Ÿä¼šè‡ªåŠ¨å°†å…¶ä¿å­˜ä¸ºæ ‡å‡†æ ¼å¼ï¼Œä»¥ä¾¿åç»­æ­¥éª¤è¿›è¡Œèåˆã€‚
        """)
        c1, c2 = st.columns([1, 1])
        with c1:
            upload_type = st.selectbox("é€‰æ‹©ä¸Šä¼ çš„æ•°æ®ç±»å‹", list(TASK_DICT.keys()), key="upload_type_sel")
            target_suffix = TASK_DICT[upload_type]
        with c2:
            # ç”Ÿæˆæ¨¡æ¿ä¸‹è½½
            st.write("ğŸ“ **æ•°æ®æ ¼å¼è¦æ±‚ï¼š**")
            st.caption("å¿…é¡»åŒ…å« `åœ°åŒº` åˆ—ï¼Œå…¶ä»–åˆ—ä¸ºç‰¹å¾æ•°å€¼ã€‚")
            # è·å–å¯¹åº”çš„æ¨¡æ¿åˆ—å
            cols = TEMPLATE_COLUMNS.get(target_suffix, TEMPLATE_COLUMNS["default"])
            template_df = pd.DataFrame(columns=cols)
            template_csv = template_df.to_csv(index=False).encode('utf-8-sig')
            st.download_button(f"ğŸ“¥ ä¸‹è½½ {upload_type} æ¨¡æ¿", template_csv, f"template_{target_suffix}.csv", "text/csv")

        uploaded_ext = st.file_uploader("ä¸Šä¼ å¤„ç†å¥½çš„æ–‡ä»¶ (.csv / .xlsx)", type=["csv", "xlsx"])
        
        if uploaded_ext:
            try:
                # è¯»å–æ–‡ä»¶
                if uploaded_ext.name.endswith('.csv'):
                    ext_df = pd.read_csv(uploaded_ext)
                else:
                    ext_df = pd.read_excel(uploaded_ext)
                # ç®€å•æ ¡éªŒ
                if "åœ°åŒº" not in ext_df.columns:
                    st.error("âŒ ä¸Šä¼ å¤±è´¥ï¼šæ–‡ä»¶ä¸­ç¼ºå°‘ `åœ°åŒº` åˆ—ï¼è¯·å‚ç…§æ¨¡æ¿æ ¼å¼ã€‚")
                    st.write("å½“å‰åˆ—å:", list(ext_df.columns))
                else:
                    # é¢„è§ˆ
                    st.write("ğŸ“Š æ•°æ®é¢„è§ˆ:", ext_df.head())
                    
                    # ä¿å­˜æŒ‰é’®
                    if st.button("ğŸ’¾ ç¡®è®¤å¹¶ä¿å­˜"):
                        target_name = f"parsed_{target_suffix}.csv"
                        save_path = os.path.join(DIRS["result"], target_name)
                        
                        # å¼ºåˆ¶è½¬ä¸º csv utf-8-sig
                        ext_df.to_csv(save_path, index=False, encoding='utf-8-sig')
                        
                        st.success(f"âœ… æ–‡ä»¶å·²ä¿å­˜ä¸º: `{target_name}`")
                        st.info("ğŸ’¡ ç°åœ¨æ‚¨å¯ä»¥å‰å¾€ **æ­¥éª¤ 4**ï¼Œè¯¥æ–‡ä»¶å°†è‡ªåŠ¨å‚ä¸æ•°æ®èåˆã€‚")
                        
            except Exception as e:
                st.error(f"æ–‡ä»¶è¯»å–å¤±è´¥: {e}")
    render_file_manager(DIRS["result"], title="å·²è§£æçš„ç»“æ„åŒ–æ•°æ®", file_ext=".csv", key_prefix="step3")
    
# # ========================================================
# # 4. æ•°æ®èåˆ
# # ========================================================
elif step == "4. æ•°æ®èåˆ&å±•ç¤º":
    st.header("ğŸ”— æ­¥éª¤ 4: å¤šæºæ•°æ®èåˆ (NÃ—d çŸ©é˜µ)åŠå¯è§†åŒ–å±•ç¤º")
    # æ‰«æå·²è§£æçš„ CSV
    csvs = [f for f in os.listdir(DIRS["result"]) if f.startswith("parsed_")]
    norm_res_path = os.path.join(DIRS["result"], "parsed_final_matrix.csv")
    raw_res_path = os.path.join(DIRS["result"], "parsed_raw_matrix.csv")
    
    if not csvs:
        st.warning("âš ï¸ æ²¡æœ‰æ‰¾åˆ°è§£æåçš„æ•°æ®æ–‡ä»¶ï¼Œè¯·å…ˆå®Œæˆæ­¥éª¤ 3ã€‚")
    else:
        st.info("ğŸ’¡ æç¤ºï¼šä¸ºäº†ä¿è¯å½’ä¸€åŒ–ç´¢å¼•æ­£ç¡®ï¼Œç³»ç»Ÿå°†æŒ‰ç…§ **[è‡ªç„¶èµ„æº -> æ½œåŠ› -> ç©ºé—´ -> é—®é¢˜ -> é¡¹ç›®]** çš„é¡ºåºå¼ºåˆ¶æ’åºã€‚")
        # === æ ¸å¿ƒé€»è¾‘ï¼šå¼ºåˆ¶æ–‡ä»¶æ’åº ===
        # å®šä¹‰æœŸæœ›çš„å…³é”®è¯é¡ºåºï¼ˆä¸ preprocess_X ä¸­çš„ç¡¬ç¼–ç ç´¢å¼•å¯¹åº”ï¼‰
        # 1.è‡ªç„¶èµ„æº: 0-3
        # 2.æ½œåŠ›: 4-22
        # 3.ç©ºé—´: 23-27
        # 4.é—®é¢˜: 28-32
        # 5.é¡¹ç›®: 33+
        order_keywords = ["landuse", "potential", "spatial", "issue", "project"]
        sorted_csvs = []
        for kw in order_keywords:
            for f in csvs:
                if kw in f and f not in sorted_csvs: sorted_csvs.append(f)
        for f in csvs:
            if f not in sorted_csvs: sorted_csvs.append(f)
        
        selected = st.multiselect("é€‰æ‹©è¦èåˆçš„æ–‡ä»¶ (å·²è‡ªåŠ¨æ’åº)", sorted_csvs, default=sorted_csvs)
        
        c1, c2 = st.columns([1, 2])
        with c1:
            use_log = st.checkbox("â˜‘ï¸ å¯ç”¨ Log1p å¯¹æ•°å˜æ¢", value=True, help="å¯¹é¢ç§¯/é‡‘é¢/æ•°é‡åˆ—è¿›è¡Œ Log(x+1) å˜æ¢ï¼Œæ‹‰è¿‘é•¿å°¾åˆ†å¸ƒçš„å·®è·ï¼Œé¿å…å°æ•°å€¼åœ¨å½’ä¸€åŒ–åå˜ä¸º0ã€‚")
        with c2:
            start_btn = st.button("å¼€å§‹èåˆä¸å½’ä¸€åŒ–", type="primary")
        if  start_btn:
            if not selected:
                st.error("è¯·è‡³å°‘é€‰æ‹©ä¸€ä¸ªæ–‡ä»¶ã€‚")
            else:
                matrices, maps, names = [], [], []
                all_feature_names = []
                # æŒ‰ç…§æ’åºåçš„ selected åˆ—è¡¨è¯»å–
                for f in selected:
                    path = os.path.join(DIRS["result"], f)
                    df = pd.read_csv(path)
                    
                    region_col = df.columns[0]
                    df = df.set_index(region_col)
                    df_num = df.select_dtypes(include=['number']).fillna(0)
                    
                    matrices.append(df_num.values)
                    maps.append({name: i for i, name in enumerate(df_num.index)})
                    
                    feat_prefix = f.replace("parsed_", "").replace(".csv", "")
                    names.append(feat_prefix)
                    all_feature_names.extend([f"{feat_prefix}:{c}" for c in df_num.columns])
                
                # 1. èåˆ
                regions, X_final, slices = unify_and_concatenate(matrices, maps, names)
                
                if len(regions) > 0:
                    st.success(f"âœ… èåˆæˆåŠŸï¼å…± {len(regions)} ä¸ªåœ°åŒºï¼Œç‰¹å¾ç»´åº¦: {X_final.shape[1]}")
                    try:
                        st.info(f"æ­£åœ¨å¤„ç†... (Logå˜æ¢: {use_log})")
                        X_norm = preprocess_X(X_final, use_log=use_log)
                        final_df = pd.DataFrame(X_norm, index=regions, columns=all_feature_names)
                        final_df.to_csv(norm_res_path, encoding='utf-8-sig')
                        
                        raw_df = pd.DataFrame(X_final, index=regions, columns=all_feature_names)
                        raw_df.to_csv(raw_res_path, encoding='utf-8-sig')
                        st.rerun()
                    except Exception as e:
                            st.error(f"å½’ä¸€åŒ–å¤±è´¥: {e}")
                else:
                        st.error("èåˆå¤±è´¥ï¼šæ‰€é€‰æ•°æ®è¡¨ä¹‹é—´æ²¡æœ‰å…¬å…±åœ°åŒºã€‚")
    # === å¯è§†åŒ–çœ‹æ¿ (æ–°å¢) ===
    if os.path.exists(norm_res_path):
        st.divider()
        st.subheader("ğŸ¨ å¤šç»´åº¦å¯è§†åŒ–çœ‹æ¿")
        
        # 1. å‡†å¤‡å¯è§†åŒ–é€‰é¡¹
        vis_options = {"ğŸ† æœ€ç»ˆèåˆçŸ©é˜µ (å½’ä¸€åŒ–)": norm_res_path}
        # è‡ªåŠ¨æ‰«æå¹¶æ·»åŠ åˆ†é¡¹æ•°æ®
        for f in sorted_csvs:
            vis_options[f"ğŸ“„ åˆ†é¡¹: {f}"] = os.path.join(DIRS["result"], f)
            
        # 2. ç”¨æˆ·é€‰æ‹©
        c_vis1, c_vis2 = st.columns([1, 2])
        with c_vis1:
            selected_vis = st.selectbox("é€‰æ‹©è¦å±•ç¤ºçš„çƒ­åŠ›å›¾æ•°æ®:", list(vis_options.keys()))
        
        # 3. åŠ è½½ä¸å¤„ç†
        target_path = vis_options[selected_vis]
        try:
            if "æœ€ç»ˆèåˆ" in selected_vis:
                df_vis = pd.read_csv(target_path, index_col=0)
                st.caption("å±•ç¤ºæœ€ç»ˆèåˆå¹¶å½’ä¸€åŒ–åçš„å…¨é‡æ•°æ®ã€‚")
            else:
                df_vis = pd.read_csv(target_path)
                if "åœ°åŒº" in df_vis.columns: df_vis = df_vis.set_index("åœ°åŒº")
                # ç­›é€‰æ•°å€¼åˆ—
                df_vis = df_vis.select_dtypes(include=['number'])
                
                with c_vis2:
                    do_norm = st.checkbox("å¯¹æ­¤æ•°æ®åº”ç”¨ Min-Max å½’ä¸€åŒ– (æ¨è)", value=True, key=f"norm_{selected_vis}")
                
                if do_norm and not df_vis.empty:
                    df_vis = (df_vis - df_vis.min()) / (df_vis.max() - df_vis.min())
                    df_vis = df_vis.fillna(0)
            
            if not df_vis.empty:
                fig = plot_heatmap(df_vis.values, df_vis.index.tolist(), feature_names=df_vis.columns.tolist())
                st.pyplot(fig)
            else:
                st.warning("è¯¥æ–‡ä»¶æ— æ•°å€¼æ•°æ®ï¼Œæ— æ³•ç»˜åˆ¶çƒ­åŠ›å›¾ã€‚")
                
        except Exception as e:
            st.error(f"å¯è§†åŒ–åŠ è½½å¤±è´¥: {e}")
    # è¿™é‡Œå±•ç¤ºçš„æ˜¯ result ç›®å½•ä¸‹çš„æ‰€æœ‰æ–‡ä»¶ï¼ˆåŒ…å« Step 3 çš„è§£ææ–‡ä»¶å’Œ Step 4 çš„çŸ©é˜µæ–‡ä»¶ï¼‰               
    render_file_manager(DIRS["result"], title="èåˆåŠä¸­é—´æ•°æ®ç®¡ç†", file_ext=".csv", key_prefix="step4")
# ========================================================
# 5. æ•°æ®åˆ†ç±»ä¸å¯¼å‡º
# ========================================================
elif step == "5. æ•°æ®åˆ†ç±»ä¸å¯¼å‡º":
    st.header("ğŸ“Š æ­¥éª¤ 5: æ™ºèƒ½åˆ†åŒºåˆ†ç±» (K-Means)")
    
    # è‡ªåŠ¨åŠ è½½ä¸Šä¸€æ­¥çš„æ–‡ä»¶
    # æ³¨æ„ï¼šè¿™é‡Œæˆ‘ä»¬ä¼˜å…ˆè¯»å– "å½’ä¸€åŒ–åçš„çŸ©é˜µ"
    auto_path = os.path.join(DIRS["result"], "parsed_final_matrix.csv")
    
    df_matrix = None
    
    # 1. æ•°æ®æºé€‰æ‹©
    data_source_opt = st.radio("æ•°æ®æ¥æº", ["è‡ªåŠ¨åŠ è½½ (æ­¥éª¤4ç»“æœ)", "æ‰‹åŠ¨ä¸Šä¼  (CSV)"])
    
    if data_source_opt == "è‡ªåŠ¨åŠ è½½ (æ­¥éª¤4ç»“æœ)":
        if os.path.exists(auto_path):
            st.success(f"âœ… å·²æ£€æµ‹åˆ°æ–‡ä»¶: parsed_final_matrix.csv")
            df_matrix = pd.read_csv(auto_path, index_col=0)
        else:
            st.warning("âš ï¸ æœªæ‰¾åˆ°è‡ªåŠ¨ç”Ÿæˆçš„æ–‡ä»¶ï¼Œè¯·å…ˆå®Œæˆæ­¥éª¤ 4 æˆ–é€‰æ‹©æ‰‹åŠ¨ä¸Šä¼ ã€‚")
    elif data_source_opt == "æ‰‹åŠ¨ä¸Šä¼  (CSV)":
        uploaded_matrix = st.file_uploader("ä¸Šä¼ ç‰¹å¾çŸ©é˜µ CSV", type=["csv"])
        if uploaded_matrix:
            df_matrix = pd.read_csv(uploaded_matrix, index_col=0)

    # 2. å¦‚æœæ•°æ®åŠ è½½æˆåŠŸï¼Œæ˜¾ç¤ºé…ç½®é¡¹
    if df_matrix is not None:
        st.divider()
        st.write(f"ğŸ“Š **å½“å‰æ•°æ®:** {df_matrix.shape[0]} ä¸ªåœ°åŒº, {df_matrix.shape[1]} ä¸ªç‰¹å¾")
        with st.expander("æŸ¥çœ‹æ•°æ®è¯¦æƒ…"):
            st.dataframe(df_matrix.head())
        
        st.subheader("ğŸ› ï¸ æ¨¡å‹å‚æ•°é…ç½®")
        col1, col2 = st.columns([1, 2])
        
        with col1:
            n_clusters = st.slider("èšç±»ç±»åˆ«æ•°ç›® (K)", min_value=2, max_value=10, value=3)
            
        with col2:
            st.markdown("**âš–ï¸ æƒé‡è®¾å®š (ä¸“å®¶æ‰“åˆ†)**")
            weight_settings = {}
            with st.expander("ç‚¹å‡»å±•å¼€è¯¦ç»†æƒé‡è®¾ç½®", expanded=True):
                c1, c2 = st.columns(2)
                with c1:
                    weight_settings["è‡ªç„¶èµ„æºç¦€èµ‹"] = st.number_input("1. è‡ªç„¶èµ„æº", value=5.0, step=0.1)
                with c2:
                    weight_settings["è‡ªç„¶èµ„æº-å¸ƒå°”é¡¹"] = st.number_input("   â†³ æ—åœ°/å¸ƒå°”", value=1.0, step=0.1)
                weight_settings["æ½œåŠ›é¡¹æ•°æ®"] = st.number_input("2. æ½œåŠ›æ•°æ®", value=1.0, step=0.1)
                c3, c4 = st.columns(2)
                with c3: weight_settings["ç©ºé—´å¸ƒå±€"] = st.number_input("3. ç©ºé—´å¸ƒå±€", value=0.1, step=0.05)
                with c4: weight_settings["å­˜åœ¨é—®é¢˜"] = st.number_input("4. å­˜åœ¨é—®é¢˜", value=0.1, step=0.05)
                weight_settings["å­é¡¹ç›®æ•°æ®"] = st.number_input("5. å­é¡¹ç›®", value=0.05, step=0.01)

        # 3. æ‰§è¡Œåˆ†æ
        if st.button("ğŸš€ å¼€å§‹èšç±»åˆ†æ", type="primary"):
            try:
                total_feats = df_matrix.shape[1]
                # æ„å»ºæƒé‡å‘é‡
                weights_vec = build_weight_vector(weight_settings, total_feats)
                
                # æ‰§è¡Œèšç±»
                labels, X_pca, X_final = perform_clustering(df_matrix, n_clusters, weights_vec)
                
                # ç»“æœå¤„ç†
                df_matrix['Cluster_ID'] = labels
                df_matrix['Cluster_Label'] = df_matrix['Cluster_ID'].apply(lambda x: f"ç±»åˆ« {x+1}")
                
                st.success("âœ… èšç±»å®Œæˆï¼")
                
                # å¯è§†åŒ–å±•ç¤º
                st.subheader("ğŸ“ˆ èšç±»ç»“æœå¯è§†åŒ– (PCA)")
                fig = plot_clusters(X_pca, labels, df_matrix.index)
                st.pyplot(fig)
                
                # ç»“æœåˆ—è¡¨
                st.subheader("ğŸ“‹ åˆ†ç±»ç»“æœè¡¨")
                st.dataframe(df_matrix[['Cluster_Label']].sort_values('Cluster_Label'))
                
                # ä¸‹è½½æŒ‰é’®
                st.download_button(
                    "ğŸ“¥ ä¸‹è½½å¸¦åˆ†ç±»ç»“æœçš„ CSV", 
                    df_matrix.to_csv(encoding='utf-8-sig'), 
                    "clustered_result.csv", 
                    "text/csv"
                )
            except Exception as e:
                st.error(f"åˆ†æå‡ºé”™: {e}")        
    # === å±•ç¤ºæ–‡ä»¶ç®¡ç† ===
    render_file_manager(DIRS["final"], title="æœ€ç»ˆåˆ†ç±»ç»“æœ", file_ext=".csv", key_prefix="step5")